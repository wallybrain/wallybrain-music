---
phase: 02-processing-pipeline
plan: 02
type: execute
wave: 2
depends_on: ["02-01"]
files_modified:
  - src/lib/server/queue.ts
  - src/lib/server/processors/processTrack.ts
  - src/routes/api/upload/+server.ts
  - src/hooks.server.ts
autonomous: true

must_haves:
  truths:
    - "An audio file POSTed to /music/api/upload returns immediately with trackId and status pending"
    - "Invalid files (wrong MIME type, no file) are rejected with 400 status and clear error message"
    - "After upload, the track status progresses from pending to processing to ready in the database"
    - "Processing produces a transcoded MP3 at /data/audio/<id>.mp3"
    - "Processing produces a peaks JSON at /data/peaks/<id>.json"
    - "Processing extracts and stores metadata (duration, bitrate, title, artist) in the database"
    - "Processing extracts and resizes cover art to /data/art/<id>.jpg when present"
    - "If processing fails, status is set to failed with an error message in the database"
    - "The queue processes tracks sequentially (one at a time) to prevent resource exhaustion"
    - "The queue resumes processing pending tracks on app restart"
  artifacts:
    - path: "src/routes/api/upload/+server.ts"
      provides: "POST endpoint for audio file upload"
      exports: ["POST"]
    - path: "src/lib/server/processors/processTrack.ts"
      provides: "Orchestrator chaining all processing steps"
      exports: ["processTrack"]
    - path: "src/lib/server/queue.ts"
      provides: "SQLite-backed sequential job queue"
      exports: ["enqueueProcessing", "startQueueProcessor"]
    - path: "src/hooks.server.ts"
      provides: "Queue startup on app initialization"
      contains: "startQueueProcessor"
  key_links:
    - from: "src/routes/api/upload/+server.ts"
      to: "src/lib/server/validators/magicBytes.ts"
      via: "validateAudioFile import"
      pattern: "validateAudioFile"
    - from: "src/routes/api/upload/+server.ts"
      to: "src/lib/server/queue.ts"
      via: "enqueueProcessing import"
      pattern: "enqueueProcessing"
    - from: "src/lib/server/processors/processTrack.ts"
      to: "src/lib/server/processors/transcode.ts"
      via: "transcodeAudio import"
      pattern: "transcodeAudio"
    - from: "src/lib/server/processors/processTrack.ts"
      to: "src/lib/server/processors/peaks.ts"
      via: "generatePeaks import"
      pattern: "generatePeaks"
    - from: "src/lib/server/processors/processTrack.ts"
      to: "src/lib/server/processors/metadata.ts"
      via: "extractMetadata import"
      pattern: "extractMetadata"
    - from: "src/lib/server/processors/processTrack.ts"
      to: "src/lib/server/processors/artwork.ts"
      via: "extractAndResizeArt import"
      pattern: "extractAndResizeArt"
    - from: "src/lib/server/processors/processTrack.ts"
      to: "src/lib/server/validators/ffprobe.ts"
      via: "validateWithFFprobe import"
      pattern: "validateWithFFprobe"
    - from: "src/lib/server/queue.ts"
      to: "src/lib/server/processors/processTrack.ts"
      via: "processTrack import"
      pattern: "processTrack"
    - from: "src/hooks.server.ts"
      to: "src/lib/server/queue.ts"
      via: "startQueueProcessor import"
      pattern: "startQueueProcessor"
---

<objective>
Wire the processing functions from Plan 02-01 into a working pipeline: upload endpoint receives files, queue manages async processing, processTrack orchestrator chains all steps, and the queue starts on app boot.

Purpose: This is the integration layer that turns independent processing functions into a working end-to-end pipeline.
Output: Working upload endpoint at /music/api/upload, background processing queue, complete processing orchestration.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-processing-pipeline/02-RESEARCH.md
@.planning/phases/02-processing-pipeline/02-01-SUMMARY.md
@src/lib/server/db/schema.ts
@src/lib/server/db/client.ts
@src/hooks.server.ts
@src/lib/server/validators/magicBytes.ts
@src/lib/server/validators/ffprobe.ts
@src/lib/server/processors/transcode.ts
@src/lib/server/processors/peaks.ts
@src/lib/server/processors/metadata.ts
@src/lib/server/processors/artwork.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Processing orchestrator and job queue</name>
  <files>
    src/lib/server/processors/processTrack.ts
    src/lib/server/queue.ts
    src/hooks.server.ts
  </files>
  <action>
**src/lib/server/processors/processTrack.ts:**
- Export `processTrack(trackId: string): Promise<void>` (note: trackId is `string`, not number -- the schema uses text UUIDs)
- Import db, tracks schema, eq from drizzle-orm
- Import all processor and validator functions from their modules (created in Plan 02-01)
- Import `writeFileSync`, `existsSync`, `mkdirSync` from `node:fs` if needed for directory creation
- Processing sequence:
  1. Update track status to `'processing'`
  2. Fetch the track record from DB to get the original file path (audioPath)
  3. Run `validateWithFFprobe(track.audioPath)` -- if invalid, throw error
  4. Transcode: `transcodeAudio(track.audioPath, '/data/audio/<trackId>.mp3')`
  5. Generate peaks: `generatePeaks('/data/audio/<trackId>.mp3', '/data/peaks/<trackId>.json')`
  6. Extract metadata: `extractMetadata(track.audioPath)` (from original for best tag data)
  7. If coverArt exists: `extractAndResizeArt(metadata.coverArt, '/data/art/<trackId>.jpg')` -- wrap in try/catch, log but do NOT fail the whole processing if cover art fails
  8. Update track in DB with:
     - `status: 'ready'`
     - `audioPath: '/data/audio/<trackId>.mp3'` (now points to transcoded file)
     - `peaksPath: '/data/peaks/<trackId>.json'`
     - `duration: probeResult.duration` (from ffprobe, in seconds as number)
     - `bitrate: 320000`
     - `title: metadata.title || track.title` (keep existing title if metadata has none)
     - `artPath: '/data/art/<trackId>.jpg'` (only if cover art succeeded)
     - `updatedAt: current timestamp`
- Wrap entire function in try/catch:
  - On error: update track with `status: 'failed'`, `errorMessage: error.message`
  - Log the error with console.error for debugging

**src/lib/server/queue.ts:**
- Export `enqueueProcessing(trackId: string): void` and `startQueueProcessor(): void`
- Use an in-process sequential queue pattern (NOT a separate job_queue table -- the track's own `status` field IS the queue state)
- `enqueueProcessing`: simply calls `processNext()` to trigger processing (the track is already in DB with status='pending' from the upload endpoint)
- `processNext()`: internal function with `isProcessing` flag guard
  1. If `isProcessing`, return immediately (another track is being processed)
  2. Query DB for first track with `status = 'pending'` ordered by `createdAt ASC`
  3. If no pending track, return
  4. Set `isProcessing = true`
  5. Call `await processTrack(track.id)` in try/finally (finally sets `isProcessing = false` and calls `setTimeout(processNext, 100)` to check for next job)
- `startQueueProcessor()`: called once on app startup
  1. Log "Queue processor started"
  2. Call `processNext()` to pick up any tracks left in 'pending' status from a previous crash
  3. Also start a `setInterval(processNext, 5000)` as a safety net to catch orphaned pending tracks (5 second interval is fine for a personal music platform)
- IMPORTANT: Also handle tracks stuck in 'processing' status on startup (from a crash mid-processing). In `startQueueProcessor`, query for tracks with `status = 'processing'` and reset them to `status = 'pending'` so they get reprocessed.

**src/hooks.server.ts (update existing):**
- The existing file runs Drizzle migrations on startup
- Add: import `{ startQueueProcessor }` from `$lib/server/queue`
- Add: call `startQueueProcessor()` AFTER the migrate() call
- Keep the existing migrate() call as-is
  </action>
  <verify>
    Run `npm run check` (svelte-check) to verify TypeScript compiles.

    Verify processTrack.ts imports all 6 processor/validator modules (grep for import lines).

    Verify hooks.server.ts calls both migrate() and startQueueProcessor().
  </verify>
  <done>
    processTrack orchestrates all processing steps in sequence with proper error handling. Queue processes tracks one at a time with crash recovery. Queue starts automatically on app boot via hooks.server.ts.
  </done>
</task>

<task type="auto">
  <name>Task 2: Upload API endpoint</name>
  <files>
    src/routes/api/upload/+server.ts
  </files>
  <action>
**src/routes/api/upload/+server.ts:**
- Export `POST` request handler (SvelteKit API route convention)
- Import: `json` from `@sveltejs/kit`, `db` from `$lib/server/db/client`, `tracks` from `$lib/server/db/schema`, `validateAudioFile` from `$lib/server/validators/magicBytes`, `enqueueProcessing` from `$lib/server/queue`
- Import: `writeFileSync`, `mkdirSync`, `existsSync` from `node:fs`
- Import: `randomUUID` from `node:crypto` for generating track IDs
- Import: `basename`, `extname` from `node:path`

Processing flow:
1. Parse `request.formData()`
2. Get `audio` field as File: `formData.get('audio') as File`
3. Validate file exists: if `!file || !file.name || file.size === 0`, return `json({ error: 'Audio file required' }, { status: 400 })`
4. Read file to Buffer: `Buffer.from(await file.arrayBuffer())`
5. Validate with magic bytes: `await validateAudioFile(buffer)`
6. If invalid, return `json({ error: validationResult.error }, { status: 400 })`
7. Generate track ID: `randomUUID()`
8. Generate slug from filename: strip extension, lowercase, replace non-alphanumeric with hyphens, trim hyphens, truncate to 100 chars. If slug is empty after sanitization, use the track ID.
9. Derive default title from filename: strip extension (e.g., "My Track.flac" -> "My Track")
10. Save original file to disk: `/data/audio/originals/<trackId><extension>` (preserve original extension). Create `/data/audio/originals/` directory if it doesn't exist.
11. Insert track into DB:
    ```
    db.insert(tracks).values({
      id: trackId,
      slug: slug,
      title: defaultTitle,
      originalFilename: file.name,
      audioPath: '/data/audio/originals/<trackId><extension>',
      status: 'pending'
    }).run();
    ```
12. Call `enqueueProcessing(trackId)` to trigger background processing
13. Return `json({ trackId, slug, status: 'pending' }, { status: 201 })`

**Slug collision handling:** If the slug already exists in DB (unique constraint violation), append a numeric suffix: `slug-2`, `slug-3`, etc. Use a simple retry loop (max 10 attempts) or catch the unique constraint error and retry with suffix.

**Important details:**
- The SvelteKit base path is `/music`, so this endpoint will be reachable at `POST /music/api/upload`
- BODY_SIZE_LIMIT is already set to 512M in docker-compose.yml and Dockerfile
- No authentication on this endpoint yet (Phase 5 adds Authelia protection). For now it's open -- this is a personal server, and the upload endpoint is internal-only until Phase 5.

After creating the endpoint, rebuild and redeploy the Docker container to test:
```
cd /home/lwb3/wallybrain-music && docker compose up -d --build
```

Test the endpoint with curl using a real audio file (if available) or a small test:
```
curl -X POST https://wallyblanchard.com/music/api/upload \
  -F "audio=@/path/to/test.mp3"
```
If no audio file is available for testing, test with a non-audio file to verify rejection:
```
curl -X POST https://wallyblanchard.com/music/api/upload \
  -F "audio=@/home/lwb3/wallybrain-music/package.json"
```
This should return 400 with an error message about unsupported format.
  </action>
  <verify>
    Run `npm run check` to verify TypeScript compiles.

    Rebuild and deploy: `cd /home/lwb3/wallybrain-music && docker compose up -d --build`

    Wait for container healthy: `docker inspect --format='{{.State.Health.Status}}' wallybrain-music`

    Test invalid file rejection:
    ```
    curl -s -X POST https://wallyblanchard.com/music/api/upload -F "audio=@/home/lwb3/wallybrain-music/package.json"
    ```
    Expected: 400 response with error about unsupported format or unknown file type.

    Test missing file:
    ```
    curl -s -X POST https://wallyblanchard.com/music/api/upload
    ```
    Expected: 400 response with "Audio file required" error.

    If a real audio file is available, test successful upload and verify:
    1. Response is 201 with trackId and status 'pending'
    2. Original file saved to /data/audio/originals/
    3. Track record created in DB with status 'pending'
    4. After a few seconds, track status progresses to 'processing' then 'ready'
    5. Transcoded MP3 exists at /data/audio/<trackId>.mp3
    6. Peaks JSON exists at /data/peaks/<trackId>.json
  </verify>
  <done>
    POST /music/api/upload accepts audio files, validates them via magic bytes, saves the original to disk, creates a DB record, and enqueues background processing. Invalid files are rejected with 400. The full pipeline processes uploads asynchronously: transcode to MP3 320k, generate peaks JSON, extract metadata, resize cover art, update DB to status=ready.
  </done>
</task>

</tasks>

<verification>
1. POST /music/api/upload returns 201 with trackId for valid audio files
2. POST /music/api/upload returns 400 for invalid/missing files with clear error messages
3. After upload, track status progresses pending -> processing -> ready in DB
4. Transcoded MP3 exists at /data/audio/<trackId>.mp3 after processing
5. Peaks JSON exists at /data/peaks/<trackId>.json after processing
6. Metadata (duration, bitrate, title) is stored in the database
7. Cover art (if present) is resized to /data/art/<trackId>.jpg
8. Processing failures result in status=failed with errorMessage in DB
9. Queue processes one track at a time
10. Queue recovers pending/stuck tracks on app restart
</verification>

<success_criteria>
A complete working processing pipeline: upload an audio file via API, receive immediate response, and background processing produces all artifacts (MP3, peaks, metadata, art) with status tracking in the database. Failed processing is recorded with error messages. The queue handles crash recovery.
</success_criteria>

<output>
After completion, create `.planning/phases/02-processing-pipeline/02-02-SUMMARY.md`
</output>
